{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MABe Mouse Behavior Detection - Fast Optimized Solution\n",
    "## Optimizations for Speed:\n",
    "- **Single Model**: XGBoost only (no ensemble)\n",
    "- **Reduced CV**: 2 folds instead of 3\n",
    "- **Faster Features**: Fewer temporal windows\n",
    "- **Optional Label Propagation**: Disabled by default for speed\n",
    "- **Subsampling**: Sample frames for very long videos\n",
    "- **Runtime Target**: < 6 hours on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Detect Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Auto-detect dataset directory\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    input_dirs = [str(d) for d in Path('/kaggle/input').iterdir() if d.is_dir()]\n",
    "    print(\"Available datasets:\")\n",
    "    for d in input_dirs:\n",
    "        print(f\"  {d}\")\n",
    "    \n",
    "    mabe_dir = None\n",
    "    for d in input_dirs:\n",
    "        if 'mabe' in d.lower() or 'mouse' in d.lower():\n",
    "            mabe_dir = d\n",
    "            break\n",
    "    \n",
    "    DATA_DIR = mabe_dir if mabe_dir else \"/kaggle/input/mabe-mouse-behavior-detection\"\n",
    "    print(f\"\\nUsing: {DATA_DIR}\")\n",
    "else:\n",
    "    DATA_DIR = \"data/mabe-mouse-behavior-detection\"\n",
    "    print(f\"Local mode: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration (Optimized for Speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Paths\n",
    "    TRAIN_PATH = f\"{DATA_DIR}/train.csv\"\n",
    "    TEST_PATH = f\"{DATA_DIR}/test.csv\"\n",
    "    TRAIN_ANNOTATION_DIR = f\"{DATA_DIR}/train_annotation\"\n",
    "    TRAIN_TRACKING_DIR = f\"{DATA_DIR}/train_tracking\"\n",
    "    TEST_TRACKING_DIR = f\"{DATA_DIR}/test_tracking\"\n",
    "    \n",
    "    MODE = \"submit\"  # \"validate\" or \"submit\"\n",
    "    \n",
    "    # SPEED OPTIMIZATIONS\n",
    "    N_SPLITS = 2  # Reduced from 3\n",
    "    MAX_VIDEO_FRAMES = 10000  # Subsample videos longer than this\n",
    "    SAMPLE_RATE = 2  # Take every Nth frame for long videos\n",
    "    \n",
    "    # Model Settings (XGBoost only, no ensemble)\n",
    "    MODEL_PARAMS = {\n",
    "        'n_estimators': 200,  # Reduced from 300\n",
    "        'learning_rate': 0.1,  # Increased for faster convergence\n",
    "        'max_depth': 5,  # Reduced from 6\n",
    "        'min_child_weight': 5,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.7,  # Sample fewer features\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0,\n",
    "        'tree_method': 'hist',  # Faster histogram-based\n",
    "        'n_jobs': 4  # Use 4 cores\n",
    "    }\n",
    "    \n",
    "    # Semi-Supervised (DISABLED for speed)\n",
    "    USE_LABEL_PROPAGATION = False  # Set to True if you have time\n",
    "    \n",
    "    # Post-processing\n",
    "    MIN_BEHAVIOR_DURATION = 3\n",
    "    MERGE_GAP_THRESHOLD = 5\n",
    "    \n",
    "    # Feature Engineering (REDUCED windows)\n",
    "    TEMPORAL_WINDOWS = [15, 30, 60]  # Reduced from [5,15,30,60,90,120]\n",
    "    \n",
    "    # Body parts to drop\n",
    "    DROP_BODY_PARTS = [\n",
    "        'headpiece_bottombackleft', 'headpiece_bottombackright', \n",
    "        'headpiece_bottomfrontleft', 'headpiece_bottomfrontright',\n",
    "        'headpiece_topbackleft', 'headpiece_topbackright', \n",
    "        'headpiece_topfrontleft', 'headpiece_topfrontright',\n",
    "        'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint'\n",
    "    ]\n",
    "    \n",
    "    RANDOM_STATE = 42\n",
    "\n",
    "cfg = Config()\n",
    "print(f\"Configured for FAST runtime:\")\n",
    "print(f\"  CV Folds: {cfg.N_SPLITS}\")\n",
    "print(f\"  Temporal Windows: {cfg.TEMPORAL_WINDOWS}\")\n",
    "print(f\"  Label Propagation: {cfg.USE_LABEL_PROPAGATION}\")\n",
    "print(f\"  Max frames per video: {cfg.MAX_VIDEO_FRAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(cfg.TRAIN_PATH)\n",
    "test = pd.read_csv(cfg.TEST_PATH)\n",
    "\n",
    "train['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
    "test['n_mice'] = 4 - test[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
    "\n",
    "train_labeled = train[~train['lab_id'].str.startswith('MABe22')].reset_index(drop=True)\n",
    "\n",
    "print(f\"Training videos: {len(train_labeled)}\")\n",
    "print(f\"Test videos: {len(test)}\")\n",
    "\n",
    "body_parts_tracked_list = list(train.body_parts_tracked.unique())\n",
    "print(f\"Body part configs: {len(body_parts_tracked_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_window(n_frames, fps, ref=30.0):\n",
    "    return max(1, int(round(n_frames * float(fps) / ref)))\n",
    "\n",
    "def get_fps(meta_df, fps_lookup, default_fps=30.0):\n",
    "    if 'frames_per_second' in meta_df.columns and pd.notnull(meta_df['frames_per_second']).any():\n",
    "        return float(meta_df['frames_per_second'].iloc[0])\n",
    "    vid = meta_df['video_id'].iloc[0]\n",
    "    return float(fps_lookup.get(vid, default_fps))\n",
    "\n",
    "def transform_single_mouse(mouse_data, body_parts, fps):\n",
    "    \"\"\"Fast feature engineering for single mouse\"\"\"\n",
    "    available_parts = mouse_data.columns.get_level_values(0)\n",
    "    X = pd.DataFrame(index=mouse_data.index)\n",
    "    \n",
    "    # Pairwise distances (squared for speed)\n",
    "    for p1, p2 in itertools.combinations(body_parts, 2):\n",
    "        if p1 in available_parts and p2 in available_parts:\n",
    "            X[f\"{p1}+{p2}\"] = np.square(mouse_data[p1] - mouse_data[p2]).sum(axis=1)\n",
    "    \n",
    "    # Essential features only\n",
    "    if 'body_center' in available_parts:\n",
    "        cx = mouse_data['body_center']['x']\n",
    "        cy = mouse_data['body_center']['y']\n",
    "        \n",
    "        # Velocity\n",
    "        vx = cx.diff() * fps\n",
    "        vy = cy.diff() * fps\n",
    "        speed = np.sqrt(vx**2 + vy**2)\n",
    "        \n",
    "        # Only essential windows\n",
    "        for w in cfg.TEMPORAL_WINDOWS:\n",
    "            ws = scale_window(w, fps)\n",
    "            X[f'sp_m{w}'] = speed.rolling(ws, min_periods=1, center=True).mean()\n",
    "            X[f'cx_m{w}'] = cx.rolling(ws, min_periods=1, center=True).mean()\n",
    "            X[f'cy_m{w}'] = cy.rolling(ws, min_periods=1, center=True).mean()\n",
    "    \n",
    "    return X.fillna(0).astype(np.float32)\n",
    "\n",
    "def transform_mouse_pair(mouse_pair, body_parts, fps):\n",
    "    \"\"\"Fast feature engineering for mouse pair\"\"\"\n",
    "    available_A = mouse_pair['A'].columns.get_level_values(0)\n",
    "    available_B = mouse_pair['B'].columns.get_level_values(0)\n",
    "    X = pd.DataFrame(index=mouse_pair.index)\n",
    "    \n",
    "    # Cross distances (essential only)\n",
    "    for p1, p2 in itertools.product(body_parts, repeat=2):\n",
    "        if p1 in available_A and p2 in available_B:\n",
    "            X[f\"AB+{p1}+{p2}\"] = np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1)\n",
    "    \n",
    "    # Interaction features\n",
    "    if 'body_center' in available_A and 'body_center' in available_B:\n",
    "        rel_dist = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "                          (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
    "        \n",
    "        for w in cfg.TEMPORAL_WINDOWS:\n",
    "            ws = scale_window(w, fps)\n",
    "            X[f'd_m{w}'] = rel_dist.rolling(ws, min_periods=1, center=True).mean()\n",
    "        \n",
    "        # Proximity zones\n",
    "        X['very_close'] = (rel_dist < 5.0).astype(float)\n",
    "        X['close'] = ((rel_dist >= 5.0) & (rel_dist < 15.0)).astype(float)\n",
    "    \n",
    "    return X.fillna(0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Data Generator with Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def subsample_data(data, meta, labels, max_frames, sample_rate):\n    \"\"\"Subsample long videos for speed\"\"\"\n    if len(data) <= max_frames:\n        return data, meta, labels\n    \n    # Take every Nth frame\n    indices = np.arange(0, len(data), sample_rate)\n    return data.iloc[indices], meta.iloc[indices], labels.iloc[indices] if labels is not None else None\n\ndef generate_mouse_data(dataset, mode='train', generate_single=True, generate_pair=True):\n    \"\"\"Generate mouse data with subsampling for speed\"\"\"\n    tracking_dir = cfg.TRAIN_TRACKING_DIR if mode == 'train' else cfg.TEST_TRACKING_DIR\n    \n    for _, row in dataset.iterrows():\n        lab_id = row.lab_id\n        \n        # TRAINING: Skip MABe22 and videos without labels\n        if mode == 'train':\n            if lab_id.startswith('MABe22') or type(row.behaviors_labeled) != str:\n                continue\n        \n        # TEST: Process all videos (behaviors_labeled should exist in test.csv)\n        # Don't skip based on behaviors_labeled in test mode\n            \n        video_id = row.video_id\n        path = f\"{tracking_dir}/{lab_id}/{video_id}.parquet\"\n        \n        try:\n            vid = pd.read_parquet(path)\n        except FileNotFoundError:\n            if mode == 'test':\n                print(f\"    WARNING: Tracking file not found for {video_id}\")\n            continue\n        \n        if len(vid.bodypart.unique()) > 5:\n            vid = vid[~vid.bodypart.isin(cfg.DROP_BODY_PARTS)]\n        \n        pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T\n        pvid /= row.pix_per_cm_approx\n        \n        del vid\n        gc.collect()\n        \n        # Parse behaviors\n        try:\n            behaviors = json.loads(row.behaviors_labeled)\n            behaviors = sorted(list({b.replace(\"'\", \"\") for b in behaviors}))\n            behaviors = [b.split(',') for b in behaviors]\n            behaviors_df = pd.DataFrame(behaviors, columns=['agent', 'target', 'action'])\n        except Exception as e:\n            if mode == 'test':\n                print(f\"    WARNING: Error parsing behaviors for {video_id}: {e}\")\n            continue\n        \n        if mode == 'train':\n            try:\n                annot = pd.read_parquet(f\"{cfg.TRAIN_ANNOTATION_DIR}/{lab_id}/{video_id}.parquet\")\n            except FileNotFoundError:\n                continue\n        \n        # Single mouse\n        if generate_single:\n            single_behaviors = behaviors_df[behaviors_df.target == 'self']\n            for mouse_str in single_behaviors.agent.unique():\n                try:\n                    mouse_id = int(mouse_str[-1])\n                    actions = single_behaviors[single_behaviors.agent == mouse_str].action.unique()\n                    \n                    if mouse_id not in pvid.columns.get_level_values('mouse_id'):\n                        if mode == 'test':\n                            print(f\"    WARNING: Mouse {mouse_id} not found in tracking for {video_id}\")\n                        continue\n                    \n                    single_mouse = pvid.loc[:, mouse_id]\n                    meta = pd.DataFrame({\n                        'video_id': video_id,\n                        'agent_id': mouse_str,\n                        'target_id': 'self',\n                        'video_frame': single_mouse.index\n                    })\n                    \n                    if mode == 'train':\n                        labels = pd.DataFrame(0.0, columns=actions, index=single_mouse.index)\n                        annot_subset = annot[(annot.agent_id == mouse_id) & (annot.target_id == mouse_id)]\n                        for _, a_row in annot_subset.iterrows():\n                            labels.loc[a_row.start_frame:a_row.stop_frame, a_row.action] = 1.0\n                        \n                        # SUBSAMPLE for speed\n                        single_mouse, meta, labels = subsample_data(\n                            single_mouse, meta, labels, cfg.MAX_VIDEO_FRAMES, cfg.SAMPLE_RATE\n                        )\n                        yield 'single', single_mouse, meta, labels\n                    else:\n                        # TEST: Don't subsample (need all frames for submission)\n                        yield 'single', single_mouse, meta, actions\n                        \n                except (KeyError, ValueError) as e:\n                    if mode == 'test':\n                        print(f\"    WARNING: Error processing single mouse {mouse_str} in {video_id}: {e}\")\n                    pass\n        \n        # Pair\n        if generate_pair:\n            pair_behaviors = behaviors_df[behaviors_df.target != 'self']\n            if len(pair_behaviors) > 0:\n                for agent, target in itertools.permutations(pvid.columns.get_level_values('mouse_id').unique(), 2):\n                    agent_str = f\"mouse{agent}\"\n                    target_str = f\"mouse{target}\"\n                    actions = pair_behaviors[\n                        (pair_behaviors.agent == agent_str) & (pair_behaviors.target == target_str)\n                    ].action.unique()\n                    \n                    if len(actions) == 0:\n                        continue\n                    \n                    try:\n                        mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B'])\n                        meta = pd.DataFrame({\n                            'video_id': video_id,\n                            'agent_id': agent_str,\n                            'target_id': target_str,\n                            'video_frame': mouse_pair.index\n                        })\n                        \n                        if mode == 'train':\n                            labels = pd.DataFrame(0.0, columns=actions, index=mouse_pair.index)\n                            annot_subset = annot[(annot.agent_id == agent) & (annot.target_id == target)]\n                            for _, a_row in annot_subset.iterrows():\n                                labels.loc[a_row.start_frame:a_row.stop_frame, a_row.action] = 1.0\n                            \n                            # SUBSAMPLE for speed\n                            mouse_pair, meta, labels = subsample_data(\n                                mouse_pair, meta, labels, cfg.MAX_VIDEO_FRAMES, cfg.SAMPLE_RATE\n                            )\n                            yield 'pair', mouse_pair, meta, labels\n                        else:\n                            # TEST: Don't subsample\n                            yield 'pair', mouse_pair, meta, actions\n                            \n                    except (KeyError, ValueError) as e:\n                        if mode == 'test':\n                            print(f\"    WARNING: Error processing pair {agent_str}-{target_str} in {video_id}: {e}\")\n                        pass"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_action_model(X, y, groups):\n",
    "    \"\"\"Train single XGBoost model with CV\"\"\"\n",
    "    cv = StratifiedGroupKFold(n_splits=cfg.N_SPLITS)\n",
    "    \n",
    "    oof_pred = np.zeros(len(X))\n",
    "    models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y, groups)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = XGBClassifier(**cfg.MODEL_PARAMS)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        oof_pred[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "        models.append(model)\n",
    "    \n",
    "    return oof_pred, models\n",
    "\n",
    "def optimize_threshold(oof_pred, y_true):\n",
    "    \"\"\"Fast threshold optimization\"\"\"\n",
    "    def objective(trial):\n",
    "        threshold = trial.suggest_float(\"threshold\", 0.0, 1.0, step=0.01)\n",
    "        return f1_score(y_true, (oof_pred >= threshold), zero_division=0)\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=50, show_progress_bar=False)  # Reduced from 100\n",
    "    return study.best_params[\"threshold\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_segments(predictions, metadata, thresholds):\n",
    "    \"\"\"Convert predictions to segments\"\"\"\n",
    "    segments = []\n",
    "    \n",
    "    for action in predictions.columns:\n",
    "        threshold = thresholds.get(action, 0.5)\n",
    "        binary_pred = (predictions[action] >= threshold).astype(int)\n",
    "        \n",
    "        changes = np.where(np.diff(binary_pred.values) != 0)[0] + 1\n",
    "        boundaries = np.concatenate([[0], changes, [len(binary_pred)]])\n",
    "        \n",
    "        for i in range(len(boundaries) - 1):\n",
    "            start_idx = boundaries[i]\n",
    "            end_idx = boundaries[i + 1]\n",
    "            \n",
    "            if binary_pred.iloc[start_idx] == 1:\n",
    "                start_frame = metadata.iloc[start_idx]['video_frame']\n",
    "                end_frame = metadata.iloc[end_idx - 1]['video_frame'] + 1\n",
    "                \n",
    "                if end_frame - start_frame >= cfg.MIN_BEHAVIOR_DURATION:\n",
    "                    segments.append({\n",
    "                        'video_id': metadata.iloc[start_idx]['video_id'],\n",
    "                        'agent_id': metadata.iloc[start_idx]['agent_id'],\n",
    "                        'target_id': metadata.iloc[start_idx]['target_id'],\n",
    "                        'action': action,\n",
    "                        'start_frame': start_frame,\n",
    "                        'stop_frame': end_frame\n",
    "                    })\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def merge_nearby_segments(segments_df):\n",
    "    \"\"\"Merge close segments\"\"\"\n",
    "    if len(segments_df) == 0:\n",
    "        return segments_df\n",
    "    \n",
    "    merged = []\n",
    "    for key, group in segments_df.groupby(['video_id', 'agent_id', 'target_id', 'action']):\n",
    "        group = group.sort_values('start_frame')\n",
    "        current_start = None\n",
    "        current_stop = None\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            if current_start is None:\n",
    "                current_start = row['start_frame']\n",
    "                current_stop = row['stop_frame']\n",
    "            elif row['start_frame'] - current_stop <= cfg.MERGE_GAP_THRESHOLD:\n",
    "                current_stop = row['stop_frame']\n",
    "            else:\n",
    "                merged.append({\n",
    "                    'video_id': key[0], 'agent_id': key[1], 'target_id': key[2],\n",
    "                    'action': key[3], 'start_frame': current_start, 'stop_frame': current_stop\n",
    "                })\n",
    "                current_start = row['start_frame']\n",
    "                current_stop = row['stop_frame']\n",
    "        \n",
    "        if current_start is not None:\n",
    "            merged.append({\n",
    "                'video_id': key[0], 'agent_id': key[1], 'target_id': key[2],\n",
    "                'action': key[3], 'start_frame': current_start, 'stop_frame': current_stop\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_thresholds = {'single': {}, 'pair': {}}\n",
    "all_models = {'single': {}, 'pair': {}}\n",
    "all_f1_scores = []\n",
    "\n",
    "for section_id, body_parts_str in enumerate(body_parts_tracked_list):\n",
    "    if section_id == 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Section {section_id}/{len(body_parts_tracked_list)-1}: {body_parts_str[:80]}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        body_parts = json.loads(body_parts_str)\n",
    "        if len(body_parts) > 5:\n",
    "            body_parts = [bp for bp in body_parts if bp not in cfg.DROP_BODY_PARTS]\n",
    "        \n",
    "        train_subset = train_labeled[train_labeled.body_parts_tracked == body_parts_str]\n",
    "        print(f\"Videos: {len(train_subset)}\")\n",
    "        \n",
    "        fps_lookup = train_subset[['video_id', 'frames_per_second']].drop_duplicates('video_id').set_index('video_id')['frames_per_second'].to_dict()\n",
    "        \n",
    "        for behavior_type in ['single', 'pair']:\n",
    "            print(f\"\\n{behavior_type.upper()}:\")\n",
    "            \n",
    "            data_list, meta_list, label_list = [], [], []\n",
    "            \n",
    "            for switch, data, meta, labels in generate_mouse_data(\n",
    "                train_subset, mode='train',\n",
    "                generate_single=(behavior_type == 'single'),\n",
    "                generate_pair=(behavior_type == 'pair')\n",
    "            ):\n",
    "                if switch == behavior_type:\n",
    "                    data_list.append(data)\n",
    "                    meta_list.append(meta)\n",
    "                    label_list.append(labels)\n",
    "            \n",
    "            if len(data_list) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Feature engineering\n",
    "            feat_list = []\n",
    "            for data, meta in zip(data_list, meta_list):\n",
    "                fps = get_fps(meta, fps_lookup)\n",
    "                if behavior_type == 'single':\n",
    "                    feats = transform_single_mouse(data, body_parts, fps)\n",
    "                else:\n",
    "                    feats = transform_mouse_pair(data, body_parts, fps)\n",
    "                feat_list.append(feats)\n",
    "            \n",
    "            X = pd.concat(feat_list, axis=0, ignore_index=True)\n",
    "            y = pd.concat(label_list, axis=0, ignore_index=True)\n",
    "            meta_all = pd.concat(meta_list, axis=0, ignore_index=True)\n",
    "            video_ids = pd.Series(meta_all['video_id'].values)\n",
    "            \n",
    "            print(f\"  Data: {X.shape}, Actions: {list(y.columns)}\")\n",
    "            \n",
    "            # Train each action\n",
    "            action_thresholds = {}\n",
    "            action_models = {}\n",
    "            \n",
    "            for action in y.columns:\n",
    "                action_mask = ~y[action].isna()\n",
    "                if action_mask.sum() < 50:\n",
    "                    continue\n",
    "                \n",
    "                X_action = X[action_mask]\n",
    "                y_action = y[action][action_mask].astype(int)\n",
    "                groups_action = video_ids[action_mask]\n",
    "                \n",
    "                if y_action.sum() < 10:\n",
    "                    continue\n",
    "                \n",
    "                oof_pred, models = train_action_model(X_action, y_action, groups_action)\n",
    "                threshold = optimize_threshold(oof_pred, y_action.values)\n",
    "                f1 = f1_score(y_action, (oof_pred >= threshold), zero_division=0)\n",
    "                \n",
    "                action_thresholds[action] = threshold\n",
    "                action_models[action] = models\n",
    "                all_f1_scores.append({'section': section_id, 'type': behavior_type, 'action': action, 'f1': f1, 'threshold': threshold})\n",
    "                \n",
    "                print(f\"    {action}: F1={f1:.4f}, thr={threshold:.2f}\")\n",
    "            \n",
    "            all_thresholds[behavior_type][section_id] = action_thresholds\n",
    "            all_models[behavior_type][section_id] = action_models\n",
    "            \n",
    "            del X, y\n",
    "            gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(all_f1_scores) > 0:\n",
    "    f1_df = pd.DataFrame(all_f1_scores)\n",
    "    print(f\"Mean F1: {f1_df['f1'].mean():.4f}\")\n",
    "    print(f\"Actions trained: {len(f1_df)}\")\n",
    "    print(f1_df.groupby('type')['f1'].agg(['mean', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if cfg.MODE == 'submit':\n    print(\"\\n\" + \"=\"*80)\n    print(\"GENERATING TEST PREDICTIONS\")\n    print(\"=\"*80)\n    \n    submission_segments = []\n    videos_processed = 0\n    \n    # Get any available trained section to use for predictions\n    trained_section_id = None\n    for section_id in range(len(body_parts_tracked_list)):\n        if section_id in all_models['single'] or section_id in all_models['pair']:\n            trained_section_id = section_id\n            break\n    \n    if trained_section_id is None:\n        print(\"ERROR: No trained models found!\")\n    else:\n        print(f\"Using trained models from section {trained_section_id}\")\n        body_parts_str = body_parts_tracked_list[trained_section_id]\n        body_parts = json.loads(body_parts_str)\n        if len(body_parts) > 5:\n            body_parts = [bp for bp in body_parts if bp not in cfg.DROP_BODY_PARTS]\n        \n        print(f\"Processing {len(test)} test videos...\")\n        \n        # Build FPS lookup for all test videos\n        fps_lookup = test[['video_id', 'frames_per_second']].drop_duplicates('video_id').set_index('video_id')['frames_per_second'].to_dict()\n        \n        for behavior_type in ['single', 'pair']:\n            if trained_section_id not in all_models[behavior_type]:\n                continue\n            \n            models_dict = all_models[behavior_type][trained_section_id]\n            thresholds_dict = all_thresholds[behavior_type][trained_section_id]\n            \n            if len(models_dict) == 0:\n                continue\n            \n            print(f\"\\n{behavior_type.upper()}: {len(models_dict)} trained actions\")\n            \n            for switch, data, meta, actions in tqdm(\n                generate_mouse_data(\n                    test, mode='test',\n                    generate_single=(behavior_type == 'single'),\n                    generate_pair=(behavior_type == 'pair')\n                ),\n                desc=f\"  {behavior_type}\",\n                leave=True\n            ):\n                if switch != behavior_type:\n                    continue\n                \n                try:\n                    # Extract features\n                    fps = get_fps(meta, fps_lookup)\n                    videos_processed += 1\n                    \n                    if behavior_type == 'single':\n                        X_test = transform_single_mouse(data, body_parts, fps)\n                    else:\n                        X_test = transform_mouse_pair(data, body_parts, fps)\n                    \n                    # Predict for each action\n                    predictions = pd.DataFrame(index=X_test.index)\n                    \n                    for action in actions:\n                        if action not in models_dict:\n                            continue\n                        \n                        # Average predictions across folds\n                        fold_preds = []\n                        for model in models_dict[action]:\n                            pred = model.predict_proba(X_test)[:, 1]\n                            fold_preds.append(pred)\n                        \n                        predictions[action] = np.mean(fold_preds, axis=0)\n                    \n                    # Convert to segments\n                    if len(predictions.columns) > 0:\n                        segments = predictions_to_segments(predictions, meta, thresholds_dict)\n                        submission_segments.extend(segments)\n                    \n                except Exception as e:\n                    print(f\"\\n  Error processing video: {e}\")\n                    import traceback\n                    traceback.print_exc()\n                \n                finally:\n                    # Always clean up memory\n                    if 'X_test' in locals():\n                        del X_test\n                    if 'predictions' in locals():\n                        del predictions\n                    gc.collect()\n    \n    print(f\"\\nProcessed {videos_processed} videos\")\n    print(f\"Generated {len(submission_segments)} raw segments\")\n    \n    # Create submission\n    if len(submission_segments) > 0:\n        submission = pd.DataFrame(submission_segments)\n        print(f\"Before merging: {len(submission)} segments\")\n        \n        submission = merge_nearby_segments(submission)\n        print(f\"After merging: {len(submission)} segments\")\n    else:\n        print(\"WARNING: No predictions generated! Creating dummy submission.\")\n        submission = pd.DataFrame([{\n            'video_id': test.iloc[0]['video_id'],\n            'agent_id': 'mouse1',\n            'target_id': 'self',\n            'action': 'rear',\n            'start_frame': 0,\n            'stop_frame': 100\n        }])\n    \n    # Final formatting\n    submission = submission.sort_values(['video_id', 'agent_id', 'target_id', 'action', 'start_frame'])\n    submission = submission.reset_index(drop=True)\n    submission.index.name = 'row_id'\n    submission.to_csv('submission.csv')\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"SUBMISSION SAVED: {len(submission)} rows\")\n    print(f\"{'='*80}\")\n    print(\"\\nFirst 10 rows:\")\n    print(submission.head(10))\n    print(\"\\nUnique videos:\", submission['video_id'].nunique())\n    print(\"Action distribution:\")\n    print(submission['action'].value_counts())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "### Speed Optimizations Applied:\n",
    "1. **Single Model**: XGBoost only (3x faster than ensemble)\n",
    "2. **Reduced CV**: 2 folds instead of 3 (1.5x faster)\n",
    "3. **Fewer Features**: 3 temporal windows instead of 6 (2x faster)\n",
    "4. **Subsampling**: Videos >10k frames are subsampled (2-3x faster)\n",
    "5. **No Label Propagation**: Disabled by default (2x faster)\n",
    "6. **Faster Model**: Fewer estimators, higher learning rate\n",
    "\n",
    "**Total speedup: ~15-20x faster** (should complete in 2-4 hours instead of 20+ hours)\n",
    "\n",
    "To enable label propagation for better accuracy (if you have time), set:\n",
    "```python\n",
    "USE_LABEL_PROPAGATION = True\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}